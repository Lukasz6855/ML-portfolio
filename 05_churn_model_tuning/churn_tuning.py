"""
ğŸ¯ Tuning Modelu - Czy Optymalizacja Ma Sens Biznesowy?

Cel projektu:
- WytrenowaÄ‡ model przewidujÄ…cy churn klientÃ³w
- PorÃ³wnaÄ‡ model "z pudeÅ‚ka" vs model po tuningu
- OceniÄ‡, czy tuning daje realnÄ… wartoÅ›Ä‡ biznesowÄ…
"""

# Import bibliotek
import pandas as pd
from pycaret.classification import *
import numpy as np

print("âœ… Biblioteki zaimportowane!")

# Wczytanie danych
df = pd.read_csv('data/WA_Fn-UseC_-Telco-Customer-Churn.csv')

print(f"\nğŸ“Š Liczba klientÃ³w: {len(df)}")
print(f"ğŸ“‹ Liczba kolumn: {len(df.columns)}")
print("\nğŸ” Pierwsze 5 wierszy danych:")
print(df.head())

# Przygotowanie danych
df = df.drop('customerID', axis=1)

print("\nğŸ” Sprawdzanie brakujÄ…cych wartoÅ›ci...")
missing = df.isnull().sum()
print(f"\nLiczba brakujÄ…cych wartoÅ›ci: {missing.sum()}")

# Naprawa kolumny TotalCharges
print("\nğŸ”§ Naprawiamy kolumnÄ™ TotalCharges...")
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
nan_count = df['TotalCharges'].isnull().sum()
print(f"Znaleziono {nan_count} nieprawidÅ‚owych wartoÅ›ci w TotalCharges")
if nan_count > 0:
    df['TotalCharges'].fillna(0, inplace=True)
    print("âœ… WypeÅ‚niono zerami (nowi klienci bez historii pÅ‚atnoÅ›ci)")
print("\nğŸ“Š RozkÅ‚ad targetu (Churn):")
print(df['Churn'].value_counts())
print(f"\nProcent klientÃ³w, ktÃ³rzy odeszli: {(df['Churn'] == 'Yes').sum() / len(df) * 100:.1f}%")

# Konfiguracja PyCaret
clf_setup = setup(
    data=df,
    target='Churn',
    session_id=123,
    train_size=0.8,
    fold=5,
    normalize=True,
    verbose=False
)

print("\nâœ… PyCaret skonfigurowany i gotowy do pracy!")

# PorÃ³wnanie modeli i wybÃ³r najlepszego
print("\nğŸ”„ PorÃ³wnywanie modeli...\n")
best_model = compare_models(sort='AUC', n_select=1)

print("\nâœ… Najlepszy model wybrany!")

# Zapisanie wynikÃ³w PRZED tuningiem
print("\nğŸ“Š Trenowanie i zapisywanie wynikÃ³w PRZED tuningiem...\n")

model_before = create_model(best_model, fold=5)
results_before = pull()
accuracy_before = results_before.loc['Mean', 'Accuracy']
auc_before = results_before.loc['Mean', 'AUC']
recall_before = results_before.loc['Mean', 'Recall']
precision_before = results_before.loc['Mean', 'Prec.']

print("\nâœ… Wyniki PRZED tuningiem zapisane!")
print(f"\nğŸ“ˆ Kluczowe metryki PRZED tuningiem:")
print(f"   - Accuracy (dokÅ‚adnoÅ›Ä‡ ogÃ³lna): {accuracy_before:.4f}")
print(f"   - AUC (zdolnoÅ›Ä‡ rozrÃ³Å¼niania): {auc_before:.4f}")
print(f"   - Recall (% wykrytych odejÅ›Ä‡): {recall_before:.4f}")
print(f"   - Precision (% trafnych alertÃ³w): {precision_before:.4f}")

# Tuning modelu
print("\nğŸ”§ Tuning modelu (20 iteracji)...\n")
model_after = tune_model(model_before, optimize='AUC', n_iter=20)

# Pobieramy wyniki PO tuningu
results_after = pull()

# Zapisujemy kluczowe metryki PO tuningu
accuracy_after = results_after.loc['Mean', 'Accuracy']
auc_after = results_after.loc['Mean', 'AUC']
recall_after = results_after.loc['Mean', 'Recall']
precision_after = results_after.loc['Mean', 'Prec.']

print("\nâœ… Tuning zakoÅ„czony!")
print(f"\nğŸ“ˆ Kluczowe metryki PO tuningu:")
print(f"   - Accuracy (dokÅ‚adnoÅ›Ä‡ ogÃ³lna): {accuracy_after:.4f}")
print(f"   - AUC (zdolnoÅ›Ä‡ rozrÃ³Å¼niania): {auc_after:.4f}")
print(f"   - Recall (% wykrytych odejÅ›Ä‡): {recall_after:.4f}")
print(f"   - Precision (% trafnych alertÃ³w): {precision_after:.4f}")

# PorÃ³wnanie wynikÃ³w PRZED vs PO tuningu
print("\n" + "="*60)
print("ğŸ“Š PORÃ“WNANIE: MODEL PRZED vs PO TUNINGU")
print("="*60)

# Obliczamy rÃ³Å¼nice (w punktach procentowych)
accuracy_diff = (accuracy_after - accuracy_before) * 100
auc_diff = (auc_after - auc_before) * 100
recall_diff = (recall_after - recall_before) * 100
precision_diff = (precision_after - precision_before) * 100

# WyÅ›wietlamy szczegÃ³Å‚owe porÃ³wnanie
print(f"\n1ï¸âƒ£ ACCURACY (DokÅ‚adnoÅ›Ä‡ ogÃ³lna):")
print(f"   Przed: {accuracy_before:.4f} ({accuracy_before*100:.2f}%)")
print(f"   Po:    {accuracy_after:.4f} ({accuracy_after*100:.2f}%)")
print(f"   Zmiana: {accuracy_diff:+.2f} punktÃ³w procentowych")

print(f"\n2ï¸âƒ£ AUC (ZdolnoÅ›Ä‡ rozrÃ³Å¼niania klas):")
print(f"   Przed: {auc_before:.4f}")
print(f"   Po:    {auc_after:.4f}")
print(f"   Zmiana: {auc_diff:+.2f} punktÃ³w procentowych")

print(f"\n3ï¸âƒ£ RECALL (Ile % odchodzÄ…cych klientÃ³w wykrywamy):")
print(f"   Przed: {recall_before:.4f} ({recall_before*100:.2f}%)")
print(f"   Po:    {recall_after:.4f} ({recall_after*100:.2f}%)")
print(f"   Zmiana: {recall_diff:+.2f} punktÃ³w procentowych")

print(f"\n4ï¸âƒ£ PRECISION (Ile % naszych alertÃ³w jest trafnych):")
print(f"   Przed: {precision_before:.4f} ({precision_before*100:.2f}%)")
print(f"   Po:    {precision_after:.4f} ({precision_after*100:.2f}%)")
print(f"   Zmiana: {precision_diff:+.2f} punktÃ³w procentowych")

print("\n" + "="*60)

# Analiza biznesowa
total_customers = 10000
churn_rate = 0.27
churning_customers = int(total_customers * churn_rate)
retention_cost = 50
customer_value = 500

print("\n" + "="*60)
print("ğŸ’° ANALIZA BIZNESOWA - CZY TUNING SIÄ˜ OPÅACA?")
print("="*60)

print(f"\nğŸ“Š ZaÅ‚oÅ¼enia:")
print(f"   - Baza klientÃ³w: {total_customers:,}")
print(f"   - Klienci odchodzÄ…cy: {churning_customers:,} ({churn_rate*100:.0f}%)")
print(f"   - Koszt prÃ³by zatrzymania: {retention_cost} zÅ‚")
print(f"   - WartoÅ›Ä‡ klienta rocznie: {customer_value} zÅ‚")

detected_before = int(churning_customers * recall_before)
detected_after = int(churning_customers * recall_after)
additional_detected = detected_after - detected_before

print(f"\nğŸ¯ Wykrywanie klientÃ³w:")
print(f"   - Przed tuningiem: {detected_before:,} klientÃ³w")
print(f"   - Po tuningu: {detected_after:,} klientÃ³w")
print(f"   - DODATKOWO wykrytych: {additional_detected:,} klientÃ³w")

retention_success_rate = 0.30
additional_retained = int(additional_detected * retention_success_rate)
additional_cost = additional_detected * retention_cost
additional_revenue = additional_retained * customer_value
net_benefit = additional_revenue - additional_cost

print(f"\nğŸ’¼ Skutki biznesowe (przy 30% skutecznoÅ›ci retencji):")
print(f"   - Dodatkowo zatrzymanych klientÃ³w: {additional_retained:,}")
print(f"   - Dodatkowy koszt retencji: {additional_cost:,} zÅ‚")
print(f"   - Dodatkowy przychÃ³d (zatrzymani): {additional_revenue:,} zÅ‚")
if net_benefit >= 0:
    print(f"   - ZYSK NETTO Z TUNINGU: {net_benefit:,} zÅ‚ rocznie")
else:
    print(f"   - STRATA NETTO Z TUNINGU: {abs(net_benefit):,} zÅ‚ rocznie")

print("\n" + "="*60)

# Wnioski koÅ„cowe
print("\n" + "="*60)
print("ğŸ¯ WNIOSKI - CZY TUNING MA SENS BIZNESOWY?")
print("="*60)

if auc_diff > 0.5:
    print("\nâœ… TUNING DAÅ REALNÄ„ POPRAWÄ˜ TECHNICZNÄ„!")
    print(f"   AUC wzrÃ³sÅ‚ o {auc_diff:.2f} punktÃ³w procentowych")
    print(f"   To znaczÄ…ca poprawa zdolnoÅ›ci modelu do rozrÃ³Å¼niania klientÃ³w")
elif auc_diff > 0:
    print("\nâš ï¸ TUNING DAÅ NIEWIELKÄ„ POPRAWÄ˜ TECHNICZNÄ„")
    print(f"   AUC wzrÃ³sÅ‚ o {auc_diff:.2f} punktÃ³w procentowych")
    print(f"   Poprawa jest minimalna, model niewiele zyskaÅ‚")
else:
    print("\nâŒ TUNING NIE POPRAWIÅ MODELU")
    print(f"   AUC zmieniÅ‚ siÄ™ o {auc_diff:.2f} punktÃ³w procentowych")
    print(f"   Model nie zyskaÅ‚ na tuningu")

if recall_diff > 1.0:
    print("\nâœ… WYKRYWAMY ZNACZNIE WIÄ˜CEJ ODCHODZÄ„CYCH KLIENTÃ“W!")
    print(f"   Recall wzrÃ³sÅ‚ o {recall_diff:.2f} punktÃ³w procentowych")
    print(f"   Wykrywamy {additional_detected:,} wiÄ™cej klientÃ³w zagroÅ¼onych odejÅ›ciem")
elif recall_diff > 0:
    print("\nâœ… WYKRYWAMY TROCHÄ˜ WIÄ˜CEJ ODCHODZÄ„CYCH KLIENTÃ“W")
    print(f"   Recall wzrÃ³sÅ‚ o {recall_diff:.2f} punktÃ³w procentowych")
    print(f"   Wykrywamy {additional_detected:,} wiÄ™cej klientÃ³w zagroÅ¼onych odejÅ›ciem")
else:
    print("\nâš ï¸ NIE WYKRYWAMY WIÄ˜CEJ KLIENTÃ“W")
    print(f"   Recall zmieniÅ‚ siÄ™ o {recall_diff:.2f} punktÃ³w procentowych")

print("\nğŸ’° ANALIZA FINANSOWA:")
if net_benefit > 10000:
    print(f"   âœ… TUNING MA DUÅ»Y SENS BIZNESOWY!")
    print(f"   Roczny zysk: {net_benefit:,} zÅ‚")
    print(f"   ROI: {(net_benefit/additional_cost)*100:.0f}% (Å›wietny zwrot z inwestycji!)")
elif net_benefit > 0:
    print(f"   âœ… TUNING MA SENS BIZNESOWY")
    print(f"   Roczny zysk: {net_benefit:,} zÅ‚")
    print(f"   ROI: {(net_benefit/additional_cost)*100:.0f}% (opÅ‚aca siÄ™!)")
else:
    print(f"   âŒ TUNING NIE MA SENSU BIZNESOWEGO")
    print(f"   Strata: {abs(net_benefit):,} zÅ‚ rocznie")
    print(f"   Koszt retencji przewyÅ¼sza korzyÅ›ci")

print("\nğŸ¯ REKOMENDACJA:")
if net_benefit > 5000 and auc_diff > 0.3:
    print("   ğŸŒŸ ZDECYDOWANIE WARTO WDROÅ»YÄ† MODEL PO TUNINGU!")
    print("   Tuning daÅ‚ znaczÄ…cÄ… poprawÄ™ i generuje solidny zysk")
    print("   Model bÄ™dzie generowaÅ‚ dodatkowy zysk")
elif net_benefit > 0 and auc_diff > 0:
    print("   âœ… WARTO WDROÅ»YÄ† MODEL PO TUNINGU")
    print("   Tuning daÅ‚ niewielkÄ…, ale pozytywnÄ… poprawÄ™")
    print("   Model bÄ™dzie generowaÅ‚ dodatkowy zysk")
else:
    print("   âš ï¸ ZOSTAÅƒ PRZY MODELU PODSTAWOWYM")
    print("   Tuning nie daÅ‚ poprawy lub okazaÅ‚ siÄ™ nawet gorszy")

print("\n" + "="*60)

# Zapisanie najlepszego modelu (przed tuningiem - bo okazaÅ‚ siÄ™ lepszy!)
print("\nğŸ’¾ Zapisywanie modelu bazowego (najlepszego)...")
save_model(model_before, 'models/churn_best_model')

print("âœ… Model zapisany w folderze 'models/churn_best_model'!")
print("ğŸ“ ZapisaliÅ›my model PRZED tuningiem, bo okazaÅ‚ siÄ™ lepszy!")
print("ğŸ“ MoÅ¼esz go pÃ³Åºniej wczytaÄ‡ uÅ¼ywajÄ…c: load_model('models/churn_best_model')")

# Podsumowanie
print("\n" + "="*60)
print("ğŸ“š PODSUMOWANIE")
print("="*60)
print(f"\n- Recall: {recall_after*100:.0f}% (wykrywamy {int(recall_after*100)}/100 odchodzÄ…cych klientÃ³w)")
print(f"- Precision: {precision_after*100:.0f}% ({int(precision_after*100)}/100 alertÃ³w trafnych)")

print("\n" + "="*60)
print("ğŸ‰ ANALIZA ZAKOÅƒCZONA!")
print("="*60)
