# ğŸ“± Churn Prediction - Przewidywanie OdejÅ›cia KlientÃ³w

## ğŸ“‹ Problem biznesowy

**Wyzwanie:**
Firma telekomunikacyjna traci klientÃ³w (churn rate ~27%). Pozyskanie nowego klienta kosztuje **5x wiÄ™cej** niÅ¼ utrzymanie obecnego. Potrzebujemy systemu wczesnego ostrzegania, ktÃ³ry zidentyfikuje klientÃ³w zagroÅ¼onych odejÅ›ciem **ZANIM** to nastÄ…pi.

**RozwiÄ…zanie:**
Model Machine Learning przewidujÄ…cy prawdopodobieÅ„stwo odejÅ›cia klienta na podstawie:
- DÅ‚ugoÅ›ci wspÃ³Å‚pracy (tenure)
- Typu umowy (miesiÄ™czna/roczna)
- Wykupionych usÅ‚ug (internet, ochrona online, itp.)
- Historii pÅ‚atnoÅ›ci

**WartoÅ›Ä‡ biznesowa:**
- ğŸ¯ Identyfikacja 75% klientÃ³w zagroÅ¼onych odejÅ›ciem
- ğŸ’° Proaktywne dziaÅ‚ania retention (oferty, rabaty, kontakt)
- ğŸ“‰ Redukcja churn o 20-30%
- ğŸ’µ ROI: KaÅ¼dy utrzymany klient = oszczÄ™dnoÅ›Ä‡ 5x kosztu akwizycji

## ğŸ”§ Technologie

- **Python 3.8+**
- **PyCaret** - AutoML dla klasyfikacji
- **Pandas** - Przetwarzanie danych
- **Scikit-learn** - Algorytmy ML, cross-validation
- **Matplotlib / Seaborn** - Wizualizacje

## ğŸ“ Struktura projektu

```
04_churn_overfitting/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv  # Dataset (~7000 klientÃ³w)
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ churn_prediction_model.pkl            # Zapisany model
â”‚
â”œâ”€â”€ churn_prediction.ipynb                    # Notebook z analizÄ… (szczegÃ³Å‚owy)
â”œâ”€â”€ churn_prediction.py                       # Skrypt Python (produkcja)
â””â”€â”€ README.md                                 # Ten plik
```

## ğŸš€ Jak uruchomiÄ‡?

### 1. Instalacja zaleÅ¼noÅ›ci

```bash
pip install pycaret pandas numpy matplotlib seaborn scikit-learn
```

### 2. Uruchomienie notebooka

OtwÃ³rz `churn_prediction.ipynb` w VS Code lub Jupyter Notebook i wykonaj kolejne komÃ³rki.

### 3. Uruchomienie skryptu Python

```bash
python churn_prediction.py
```

## ğŸ“Š Dane

**Å¹rÃ³dÅ‚o:** Telco Customer Churn Dataset (IBM)

**Rozmiar:** 7043 klientÃ³w, 20 cech

**Cechy:**
- **Demograficzne:** gender, SeniorCitizen, Partner, Dependents
- **UsÅ‚ugi:** PhoneService, InternetService, OnlineSecurity, TechSupport, StreamingTV, etc.
- **Umowa:** Contract (Month-to-month, One year, Two year)
- **PÅ‚atnoÅ›ci:** PaymentMethod, MonthlyCharges, TotalCharges
- **Target:** Churn (Yes/No)

**RozkÅ‚ad:**
- No (Klient zostaÅ‚): 73%
- Yes (Klient odszedÅ‚): 27%

## ğŸ¯ Proces analizy

1. **Wczytanie i eksploracja danych**
2. **Czyszczenie danych** (TotalCharges, usuniÄ™cie customerID)
3. **Setup PyCaret** z cross-validation (5-fold)
4. **PorÃ³wnanie ~15 algorytmÃ³w ML** (uÅ¼ywajÄ…c CV, nie training accuracy!)
5. **WybÃ³r najlepszego modelu** (bazujÄ…c na AUC)
6. **Demonstracja overfittingu** (przepasowany Decision Tree)
7. **Test na zbiorze testowym** (20% danych)
8. **Analiza feature importance**
9. **Wizualizacje** (confusion matrix, ROC curve)
10. **Zapis modelu** i przykÅ‚ad uÅ¼ycia

## âš ï¸ Jak unikamy overfittingu

### Problem: Overfitting

**Overfitting** = model "zapamiÄ™tuje" dane treningowe zamiast uczyÄ‡ siÄ™ wzorcÃ³w.

**Objawy:**
- Training Accuracy: 99% ğŸ˜ƒ
- Cross-Validation: 60% ğŸ˜±
- W produkcji: Model zawodzi âŒ

### Nasze podejÅ›cie: Cross-Validation

**Cross-Validation (5-fold):**

```
Dzielimy dane treningowe na 5 czÄ™Å›ci:

Fold 1: [TEST] [TRAIN] [TRAIN] [TRAIN] [TRAIN] â†’ accuracy: 84%
Fold 2: [TRAIN] [TEST] [TRAIN] [TRAIN] [TRAIN] â†’ accuracy: 86%
Fold 3: [TRAIN] [TRAIN] [TEST] [TRAIN] [TRAIN] â†’ accuracy: 83%
Fold 4: [TRAIN] [TRAIN] [TRAIN] [TEST] [TRAIN] â†’ accuracy: 85%
Fold 5: [TRAIN] [TRAIN] [TRAIN] [TRAIN] [TEST] â†’ accuracy: 84%

Åšrednia: 84.4% Â± 1.2% (to prawdziwy wynik!)
```

**Dlaczego to dziaÅ‚a?**
- Model testowany na danych, ktÃ³rych **NIE widziaÅ‚** podczas treningu
- Symuluje dziaÅ‚anie w produkcji
- Niskie odchylenie standardowe = model stabilny

### Demonstracja overfittingu

W projekcie pokazujemy przykÅ‚ad **przepasowanego modelu:**

**Model bez ograniczeÅ„ (Decision Tree, max_depth=None):**
- Training Accuracy: **99.75%**
- Cross-Validation: **72.40%**
- **RÃ³Å¼nica: 27.35%** ğŸš¨ OVERFITTING!

**Dobry model (Gradient Boosting):**
- Training Accuracy: **~80%**
- Cross-Validation: **79.93%**
- **RÃ³Å¼nica: <1%** âœ… Stabilny!

### Praktyczne zasady:

âœ… **ZAWSZE uÅ¼ywaj cross-validation** do oceny modelu
âœ… **RÃ³Å¼nica < 5%** miÄ™dzy training a CV = OK
âš ï¸ **RÃ³Å¼nica 5-10%** = lekki overfitting
ğŸš¨ **RÃ³Å¼nica > 10%** = powaÅ¼ny overfitting

âœ… **Testuj na zbiorze testowym** (dane, ktÃ³rych model NIGDY nie widziaÅ‚)
âœ… **PorÃ³wnaj:** CV accuracy â‰ˆ Test accuracy â†’ model OK
âŒ **Unikaj:** CV accuracy >> Test accuracy â†’ overfitting

## ğŸ“ˆ Wyniki

### Najlepsze modele (sortowane po AUC):

Rzeczywiste wyniki z wykonania notebooka:

| Model | Accuracy | AUC | Recall | Precision | F1 | TT (Sec) |
|-------|----------|-----|--------|-----------|----|----|  
| **Gradient Boosting** | **0.7993** | **0.8463** | **0.7993** | **0.7903** | **0.7924** | **0.41** |
| Logistic Regression | 0.8039 | 0.8457 | 0.8039 | 0.7967 | 0.7985 | 1.40 |
| Ada Boost | 0.8019 | 0.8441 | 0.8019 | 0.7936 | 0.7953 | 0.25 |
| Ridge Classifier | 0.8003 | 0.8373 | 0.8003 | 0.7908 | 0.7921 | 0.14 |
| LightGBM | 0.7900 | 0.8359 | 0.7900 | 0.7811 | 0.7837 | 0.30 |
| Random Forest | 0.7913 | 0.8248 | 0.7913 | 0.7802 | 0.7823 | 0.26 |

**Metryki:**
- **Accuracy:** ~79.93% (wynik ogÃ³lny)
- **AUC:** ~0.8463 (bardzo dobry - idealny = 1.0)
- **Recall:** ~79.93% (wykrywamy prawie 80% klientÃ³w, ktÃ³rzy odejdÄ…)
- **Precision:** ~79.03% (prawie 80% naszych alertÃ³w jest prawidÅ‚owych)

**Na 100 klientÃ³w, ktÃ³rzy faktycznie odejdÄ…:**
- âœ… Wykryjemy: **~80 klientÃ³w** (Recall = 79.93%)
- âŒ Przegapimy: **~20 klientÃ³w**

**Na 100 alertÃ³w "klient odejdzie":**
- âœ… PrawidÅ‚owe alarmy: **~79** (Precision = 79.03%)
- âŒ FaÅ‚szywe alarmy: **~21**

**Czy to dobre?**
TAK! Bo:
- Koszt faÅ‚szywego alarmu: Niepotrzebny telefon/oferta (~10 zÅ‚)
- Koszt przegapienia klienta: Utrata klienta (~500 zÅ‚)
- Stosunek 1:50 - warto dziaÅ‚aÄ‡ nawet z niÅ¼szÄ… precision!

## ğŸ¯ NajwaÅ¼niejsze cechy (Feature Importance)

### Top 5 cech wpÅ‚ywajÄ…cych na churn:

1. **Contract (typ umowy)** ğŸ†
   - Month-to-month = wysokie ryzyko
   - Akcja: ZachÄ™caj do umÃ³w dÅ‚ugoterminowych

2. **tenure (dÅ‚ugoÅ›Ä‡ wspÃ³Å‚pracy)**
   - Nowi klienci (< 6 miesiÄ™cy) = wysokie ryzyko
   - Akcja: Program onboarding dla nowych klientÃ³w

3. **TotalCharges (caÅ‚kowite opÅ‚aty)**
   - Niskie = krÃ³tka historia = ryzyko
   - Akcja: Buduj lojalnoÅ›Ä‡ od poczÄ…tku

4. **InternetService**
   - Fiber optic = wyÅ¼sze ryzyko (wysokie ceny?)
   - Akcja: SprawdÅº konkurencjÄ™, dostosuj ofertÄ™

5. **MonthlyCharges (opÅ‚ata miesiÄ™czna)**
   - Wysokie opÅ‚aty = wiÄ™ksze ryzyko
   - Akcja: Oferty value-for-money

### ğŸ¯ Profil klienta wysokiego ryzyka:

- ğŸš¨ Nowy klient (tenure < 6 miesiÄ™cy)
- ğŸš¨ Umowa miesiÄ™czna (Month-to-month)
- ğŸš¨ Internet Å›wiatÅ‚owodowy (Fiber optic)
- ğŸš¨ Brak dodatkowych usÅ‚ug (OnlineSecurity, TechSupport)
- ğŸš¨ PÅ‚atnoÅ›Ä‡ czekiem elektronicznym

### ğŸ’¡ Rekomendacje dla dziaÅ‚u retention:

**Proaktywne dziaÅ‚ania:**
1. â˜ï¸ Kontakt po 3 miesiÄ…cach wspÃ³Å‚pracy
2. ğŸ’° Rabat za przejÅ›cie na umowÄ™ rocznÄ… (15-20%)
3. ğŸ Darmowe dodatkowe usÅ‚ugi na 3 miesiÄ…ce
4. ğŸ“Š Regularne badanie satysfakcji
5. ğŸ¯ Personalizowane oferty (dopasowane do profilu)

**Monitoring:**
- Dashboard z real-time ryzykiem churn
- Cotygodniowe raporty dla dziaÅ‚u CS
- Alerty dla klientÃ³w z prawdopodobieÅ„stwem > 70%

## ğŸ”® PrzykÅ‚ad uÅ¼ycia w produkcji

### Przewidywanie dla nowego klienta:

```python
# Wczytaj model
loaded_model = load_model('models/churn_prediction_model')

# Profil nowego klienta
new_customer = pd.DataFrame({
    'tenure': [2],  # 2 miesiÄ…ce
    'Contract': ['Month-to-month'],
    'InternetService': ['Fiber optic'],
    'MonthlyCharges': [70.0],
    # ... inne cechy
})

# Przewidywanie
prediction = predict_model(loaded_model, data=new_customer)
churn_prob = prediction['prediction_score'].values[0]

# PrzykÅ‚ad z notebooka: churn_prob = 0.689 (68.9%)

if churn_prob > 0.7:
    # WYSOKI RISK - natychmiastowa akcja!
    trigger_retention_campaign(customer_id)
elif churn_prob > 0.5:
    # ÅšREDNIE RYZYKO - monitoring (jak w naszym przykÅ‚adzie: 68.9%)
    add_to_watchlist(customer_id)
```

### Integracja z systemami:

1. **CRM** - Real-time scoring podczas interakcji z klientem
2. **Marketing Automation** - Automatyczne kampanie retention
3. **Call Center** - Priorytetyzacja poÅ‚Ä…czeÅ„ od klientÃ³w wysokiego ryzyka
4. **Billing System** - Automatyczne oferty rabatowe

## ğŸ’¡ Wnioski

### 1. Model o nieco niÅ¼szym accuracy, ale stabilnych wynikach jest lepszy biznesowo

**PorÃ³wnanie:**

**Model A (Overfitted - Decision Tree bez ograniczeÅ„):**
- Training: 99.75%
- CV: 72.40%
- Test: NIE WDRAÅ»AMY (zbyt duÅ¼a rÃ³Å¼nica!)
- **Problem:** Niestabilny, rÃ³Å¼nica 27.35% wskazuje na powaÅ¼ny overfitting

**Model B (Stabilny - Gradient Boosting):**
- Training: ~80%
- CV: 79.93%
- Test: 79.91%
- **Zaleta:** Przewidywalny, stabilne wyniki ~80%

**Dla biznesu:**
- Lepiej mieÄ‡ **pewne 79.93%** niÅ¼ **niepewne 72-99%**
- Planowanie budÅ¼etu retention wymaga stabilnoÅ›ci
- Model stabilny = Å‚atwiejszy do monitorowania i utrzymania
- Nasz model: CV = 79.93%, Test = 79.91% â†’ doskonaÅ‚a zgodnoÅ›Ä‡!

### 2. Cross-Validation to klucz do unikniÄ™cia overfittingu

**Training Accuracy = Oszustwo:**
- Model testowany na danych, ktÃ³re "widziaÅ‚"
- Jak egzamin z tych samych pytaÅ„, ktÃ³re byÅ‚y na lekcji
- Nie mÃ³wi NIC o dziaÅ‚aniu w praktyce

**Cross-Validation = Prawda:**
- Model testowany na NOWYCH danych
- Symuluje warunki produkcyjne
- Pokazuje prawdziwe moÅ¼liwoÅ›ci modelu

### 3. Prostsze modele czÄ™sto lepsze w produkcji

**Zalety prostszych modeli:**
- âœ… Szybsze trenowanie i predykcja
- âœ… Åatwiejsza interpretacja (waÅ¼ne dla biznesu!)
- âœ… Mniejsze ryzyko overfittingu
- âœ… Prostsze w utrzymaniu
- âœ… NiÅ¼sze wymagania sprzÄ™towe

**PrzykÅ‚ad z naszego projektu:**
- Logistic Regression (prostszy): 80.39% accuracy, 1.4s treningu, peÅ‚na interpretowalnoÅ›Ä‡
- Gradient Boosting (zÅ‚oÅ¼ony): 79.93% accuracy, 0.41s treningu, mniejsza interpretowalnoÅ›Ä‡
- **RÃ³Å¼nica 0.46% vs interpretowalnoÅ›Ä‡** - oba modele sÄ… dobre!

### 4. Interpretacja modelu = wartoÅ›Ä‡ dla biznesu

**Z Feature Importance wiemy:**
- Å»e contract i tenure sÄ… najwaÅ¼niejsze
- Na co patrzeÄ‡ przy identyfikacji ryzyka
- Gdzie inwestowaÄ‡ w retention (nowi klienci!)
- Jak personalizowaÄ‡ oferty

**Model z 85% accuracy + interpretacja >> Model z 90% accuracy bez interpretacji**

### 5. Monitoring w produkcji jest kluczowy

**Plan monitoringu:**
- ğŸ“Š Tygodniowe raporty accuracy
- ğŸ”” Alerty gdy accuracy spada > 5%
- ğŸ”„ Retrenowanie co 3 miesiÄ…ce
- ğŸ“ˆ A/B testing strategii retention
- ğŸ’° Tracking ROI (koszt modelu vs oszczÄ™dnoÅ›ci)

## ğŸ“š MoÅ¼liwe rozszerzenia

- [ ] **Real-time API** - Endpoint do przewidywaÅ„ w czasie rzeczywistym
- [ ] **Dashboard** - Streamlit/Dash z wizualizacjÄ… ryzyka
- [ ] **A/B Testing** - PorÃ³wnanie strategii retention
- [ ] **SHAP values** - WyjaÅ›nienia pojedynczych przewidywaÅ„
- [ ] **Model retraining pipeline** - Automatyczne uczenie na nowych danych
- [ ] **Customer Lifetime Value** - Priorytetyzacja klientÃ³w wedÅ‚ug wartoÅ›ci
- [ ] **Segmentacja** - RÃ³Å¼ne strategie dla rÃ³Å¼nych segmentÃ³w
- [ ] **Time-series analysis** - Przewidywanie momentu odejÅ›cia

## ğŸ“ Kluczowe lekcje z projektu

### Dla Data Scientists:

1. **Cross-validation > Training accuracy** - zawsze!
2. **Overfitting detection** - monitoruj rÃ³Å¼nicÄ™ miÄ™dzy train a CV
3. **StabilnoÅ›Ä‡ > Maksymalna accuracy** - w produkcji liczy siÄ™ przewidywalnoÅ›Ä‡
4. **Feature importance** - interpretacja = wartoÅ›Ä‡ biznesowa

### Dla Biznesu:

1. **ProaktywnoÅ›Ä‡ > ReaktywnoÅ›Ä‡** - wczesne wykrycie = oszczÄ™dnoÅ›ci
2. **Model to narzÄ™dzie, nie cel** - liczy siÄ™ ROI, nie accuracy
3. **FaÅ‚szywe alarmy < Przegapione klienty** - lepiej przebadaÄ‡ 100 niÅ¼ straciÄ‡ 10
4. **Personalizacja** - rÃ³Å¼ni klienci = rÃ³Å¼ne strategie retention

## ğŸ“ Autor

Projekt stworzony w ramach kursu Machine Learning - demonstracja problemu overfittingu i znaczenia cross-validation.

## ğŸ“„ Licencja

Projekt edukacyjny - dane publiczne (Telco Customer Churn Dataset)
