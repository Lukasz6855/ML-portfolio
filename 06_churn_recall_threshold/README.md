# ğŸ¯ Projekt 6: Threshold Analysis - Recall vs Precision w Churn Prediction

## ğŸ“‹ Opis projektu

Projekt analizuje **wpÅ‚yw threshold (progu decyzyjnego)** na trade-off miÄ™dzy **Recall a Precision** w problemie churn prediction. Pokazuje jak wybÃ³r progu wpÅ‚ywa na liczbÄ™ wykrytych klientÃ³w odchodzÄ…cych vs liczbÄ™ faÅ‚szywych alarmÃ³w.

**Kluczowe pytania:**
1. Czy tuning modelu pod kÄ…tem Recall faktycznie poprawia wyniki?
2. Jak threshold wpÅ‚ywa na confusion matrix?
3. KtÃ³ry threshold jest najlepszy biznesowo?
4. Dlaczego w churn prediction czÄ™sto lepiej wybraÄ‡ niÅ¼szy threshold?

---

## ğŸ¯ Cel analizy

- **PorÃ³wnaÄ‡ model bazowy vs tuned** pod kÄ…tem Recall
- **PrzeanalizowaÄ‡ 3 thresholdy**: 0.3 (liberalny), 0.5 (standardowy), 0.7 (konserwatywny)
- **ObliczyÄ‡ koszty biznesowe** dla rÃ³Å¼nych thresholdÃ³w
- **WyjaÅ›niÄ‡ trade-off** miÄ™dzy Recall a Precision w kontekÅ›cie biznesowym

---

## ğŸ“Š Dataset

**Telco Customer Churn Dataset**
- Å¹rÃ³dÅ‚o: Kaggle / IBM Watson Analytics
- Liczba rekordÃ³w: 7,043 klientÃ³w
- Liczba cech: 19 (po usuniÄ™ciu `customerID`)
- Target: `Churn` (Yes/No)
- RozkÅ‚ad: ~27% klientÃ³w odchodzÄ…cych

**Kluczowe cechy:**
- `tenure` - ile miesiÄ™cy klient jest w firmie
- `MonthlyCharges` - miesiÄ™czny rachunek
- `TotalCharges` - Å‚Ä…czne pÅ‚atnoÅ›ci
- `Contract` - typ umowy (Month-to-month, One year, Two year)
- `InternetService` - rodzaj internetu
- `PaymentMethod` - metoda pÅ‚atnoÅ›ci

---

## ğŸ”§ Metodologia

### 1. Przygotowanie danych
- UsuniÄ™cie kolumny `customerID`
- Konwersja `TotalCharges` na typ numeryczny
- WypeÅ‚nienie brakujÄ…cych wartoÅ›ci zerem

### 2. Konfiguracja PyCaret
```python
setup(
    data=df,
    target='Churn',
    session_id=123,
    train_size=0.8,      # 80% trening, 20% test
    fold=5,              # 5-fold cross-validation
    normalize=True       # Normalizacja cech numerycznych
)
```

### 3. WybÃ³r i trening modelu
- **Algorytm:** `compare_models(sort='Recall')` â†’ wybÃ³r najlepszego pod kÄ…tem Recall
- **Model bazowy:** Gradient Boosting Classifier
- **Tuning:** `tune_model(optimize='Recall', n_iter=20)` - optymalizacja hiperparametrÃ³w

### 4. Analiza thresholdÃ³w
Testowane progi decyzyjne:
- **0.3** - Liberalny (wiÄ™cej alarmÃ³w)
- **0.5** - Standardowy (domyÅ›lny)
- **0.7** - Konserwatywny (maÅ‚o alarmÃ³w)

---

## ğŸ“ˆ Wyniki

### ğŸ”§ Tuning vs Model Bazowy

| Metryka | Model Bazowy | Model po Tuningu | Zmiana |
|---------|--------------|------------------|--------|
| **Recall** | 0.8468 | 0.8481 | +0.13 p.p. |
| **Precision** | 0.6766 | 0.6779 | +0.13 p.p. |
| **Accuracy** | 0.8124 | 0.8131 | +0.07 p.p. |
| **AUC** | 0.8463 | 0.8471 | +0.08 p.p. |

**ğŸ¯ DECYZJA: TUNING NIE WART ZACHODU**

âŒ Recall poprawiÅ‚ siÄ™ tylko o **0.13 p.p.** (< 1.0 p.p. prÃ³g akceptacji)  
âœ… **UÅ¼ywamy modelu bazowego** - prostszy, szybszy, rÃ³wnie dobry

**Wnioski:**
- Tuning nie daÅ‚ znaczÄ…cej poprawy Recall
- Model bazowy ma wystarczajÄ…cÄ… jakoÅ›Ä‡ (Recall ~85%)
- Dodatkowa zÅ‚oÅ¼onoÅ›Ä‡ tuningu nie jest uzasadniona

---

### ğŸ¯ Analiza ThresholdÃ³w

#### Confusion Matrix dla rÃ³Å¼nych thresholdÃ³w

| Threshold | TN | FP | FN | TP | Recall | Precision | Accuracy |
|-----------|----|----|----|----|--------|-----------|----------|
| **0.3** | 970 | 70 | 61 | 308 | **83.47%** | 81.48% | 90.70% |
| **0.5** | 970 | 70 | 61 | 308 | **83.47%** | 81.48% | 90.70% |
| **0.7** | 1017 | 23 | 116 | 253 | **68.56%** | 91.67% | 90.13% |

**âš ï¸ KLUCZOWA OBSERWACJA:**

Threshold **0.3 i 0.5 dajÄ… IDENTYCZNE wyniki**! Dlaczego?

Model ma **polaryzowany rozkÅ‚ad prawdopodobieÅ„stw**:
- `< 0.3`: **0 klientÃ³w**
- `0.3-0.5`: **0 klientÃ³w**
- `0.5-0.7`: **434 klientÃ³w**
- `â‰¥ 0.7`: **975 klientÃ³w**

**Wszystkie przewidywania â‰¥ 0.5!** Model jest bardzo pewny swoich decyzji.

---

### ğŸ’° Analiza Biznesowa

#### ZaÅ‚oÅ¼enia kosztowe:
- **Koszt faÅ‚szywego alarmu (FP):** 20 zÅ‚ (telefon + czas konsultanta)
- **Koszt przegapienia klienta (FN):** 500 zÅ‚ (utrata wartoÅ›ci rocznej)
- **Koszt prÃ³by retencji (TP):** 50 zÅ‚ (telefon + oferta)
- **SkutecznoÅ›Ä‡ retencji:** 30% (zatrzymujemy 30% z TP)
- **WartoÅ›Ä‡ zatrzymanego klienta:** 500 zÅ‚

#### Wyniki finansowe:

| Threshold | Koszty ÅÄ…cznie | Przychody | **Zysk Netto** |
|-----------|----------------|-----------|----------------|
| **0.3** | 20,850 zÅ‚ | 46,200 zÅ‚ | **+25,350 zÅ‚** âœ… |
| **0.5** | 20,850 zÅ‚ | 46,200 zÅ‚ | **+25,350 zÅ‚** âœ… |
| **0.7** | 39,260 zÅ‚ | 37,950 zÅ‚ | **-1,310 zÅ‚** âŒ |

**SzczegÃ³Å‚owa analiza threshold 0.7 (konserwatywny):**
- âŒ **116 przegapionych klientÃ³w** (FN) â†’ koszt: 58,000 zÅ‚
- âœ… Tylko 23 faÅ‚szywe alarmy (FP) â†’ oszczÄ™dnoÅ›Ä‡: 940 zÅ‚ vs threshold 0.5
- **Bilans:** OszczÄ™dnoÅ›Ä‡ 940 zÅ‚ na FP < Strata 27,500 zÅ‚ na FN
- **Wynik:** -1,310 zÅ‚ (strata!)

---

## ğŸ“ Kluczowe Wnioski

### 1. Tuning - Czy warto?

**âŒ NIE w tym przypadku**

- Poprawa Recall: +0.13 p.p. (< 1% prÃ³g)
- Model bazowy ma juÅ¼ wysoki Recall (~85%)
- Tuning dodaje zÅ‚oÅ¼onoÅ›Ä‡ bez znaczÄ…cej korzyÅ›ci
- **Rekomendacja:** UÅ¼ywaj modelu bazowego

### 2. Trade-off Recall vs Precision

| Threshold | Charakterystyka | Kiedy uÅ¼ywaÄ‡? |
|-----------|----------------|---------------|
| **0.3-0.4** | ğŸŸ¢ Wysoki Recall<br>ğŸ”´ Niski Precision | Koszt przegapienia >> Koszt alarmu |
| **0.5** | ğŸŸ¡ Balans | Standardowe podejÅ›cie |
| **0.7+** | ğŸ”´ Niski Recall<br>ğŸŸ¢ Wysoki Precision | Koszt alarmu >> Koszt przegapienia |

### 3. Dlaczego w churn zazwyczaj niÅ¼szy threshold?

**Stosunek kosztÃ³w: 1:25**
- FaÅ‚szywy alarm: 20 zÅ‚
- Przegapienie: 500 zÅ‚

**Lepiej 10 niepotrzebnych telefonÃ³w niÅ¼ straciÄ‡ 1 klienta!**

**Analogia:** Wykrywacz dymu w domu
- Wolisz 10 faÅ‚szywych alarmÃ³w niÅ¼ przegapiÄ‡ poÅ¼ar
- Tak samo w churn: wolisz 10 niepotrzebnych telefonÃ³w niÅ¼ straciÄ‡ klienta

### 4. Polaryzowany rozkÅ‚ad prawdopodobieÅ„stw

**W naszym modelu:**
- Wszystkie przewidywania â‰¥ 0.5
- Threshold 0.3 = Threshold 0.5 (identyczne wyniki!)
- **Wniosek:** Zostaw threshold 0.5 (domyÅ›lny)

Zmiana thresholdu z 0.5 na 0.3 nie wpÅ‚ynÄ™Å‚a na wyniki, poniewaÅ¼ model nie przypisuje Å¼adnym klientom prawdopodobieÅ„stw churn poniÅ¼ej 0.5. Dopiero podniesienie thresholdu do 0.7 spowodowaÅ‚o spadek recall, eliminujÄ…c klientÃ³w o umiarkowanym ryzyku odejÅ›cia.

Threshold dziaÅ‚a tylko tam, gdzie model jest â€niepewnyâ€

---

## ğŸ“Š Wizualizacje

### Confusion Matrix dla rÃ³Å¼nych thresholdÃ³w

```
THRESHOLD 0.5 (WYBRANE)               THRESHOLD 0.7
Recall: 83.47% | Precision: 81.48%   Recall: 68.56% | Precision: 91.67%

           Przewidywane                      Przewidywane
           No      Yes                       No      Yes
Real No   970      70                 Real No  1017     23
    Yes    61     308                     Yes  116    253
```

**Threshold 0.7:**
- âœ… Mniej faÅ‚szywych alarmÃ³w: 23 vs 70 (-67%)
- âŒ WiÄ™cej przegapionych: 116 vs 61 (+90%)
- ğŸ’¸ Finansowo gorsze: -1,310 zÅ‚ straty!

---

## ğŸš€ Rekomendacje Biznesowe

### âœ… Co wdroÅ¼yÄ‡:

1. **Model:** Gradient Boosting Classifier (bazowy, bez tuningu)
2. **Threshold:** 0.5 (domyÅ›lny) - w naszym przypadku identyczny z 0.3
3. **Strategia:** Priorytet dla Recall (wykrycie klientÃ³w odchodzÄ…cych)

### ğŸ“ Akcje retencyjne:

Dla klientÃ³w z prawdopodobieÅ„stwem odejÅ›cia â‰¥ 0.5:
- Telefon z dziaÅ‚em retencji
- Oferta specjalna / rabat
- Analiza przyczyn niezadowolenia
- Follow-up po 2 tygodniach

### ğŸ“ˆ Oczekiwane wyniki:

**MiesiÄ™cznie (zakÅ‚adajÄ…c 1,409 klientÃ³w testowych):**
- Wykryte zagroÅ¼enia: **308 klientÃ³w**
- FaÅ‚szywe alarmy: **70 klientÃ³w** (koszty: 1,400 zÅ‚)
- Zatrzymani klienci: **~92 klientÃ³w** (30% z 308)
- **Zysk netto: +25,350 zÅ‚ miesiÄ™cznie**

**Rocznie:**
- **OszczÄ™dzone straty: ~304,200 zÅ‚**
- Koszt faÅ‚szywych alarmÃ³w: ~16,800 zÅ‚
- **ROI: ~1,700%**

---

## ğŸ’¡ NajwaÅ¼niejsza Lekcja

**W churn prediction:**

ğŸ”´ **Koszt przegapienia > Koszt faÅ‚szywego alarmu**

Dlatego:
- âœ… Optymalizuj pod **Recall** (nie AUC!)
- âœ… UÅ¼ywaj **niÅ¼szego threshold** (0.3-0.5)
- âœ… Toleruj faÅ‚szywe alarmy
- âŒ NIE optymalizuj pod Precision

**PamiÄ™taj:** Lepiej niepotrzebnie zadzwoniÄ‡ do 10 klientÃ³w, niÅ¼ straciÄ‡ 1 wartoÅ›ciowego klienta!

---

## ğŸ“ Struktura projektu

```
06_churn_recall_threshold/
â”œâ”€â”€ README.md                           # Ten plik
â”œâ”€â”€ churn_recall_threshold.ipynb       # Notebook z peÅ‚nÄ… analizÄ…
â”œâ”€â”€ churn_recall_threshold.py          # Skrypt Python
â”œâ”€â”€ data/
â”‚   â””â”€â”€ WA_Fn-UseC_-Telco-Customer-Churn.csv
â””â”€â”€ models/                            # (modele zapisane przez PyCaret)
```

---

## ğŸ› ï¸ Technologie

- **Python 3.8+**
- **PyCaret 3.x** - AutoML
- **Pandas** - manipulacja danymi
- **Scikit-learn** - metryki ML
- **Matplotlib / Seaborn** - wizualizacje

---

## ğŸ¯ NastÄ™pne kroki

Potencjalne rozszerzenia projektu:

1. **Kalibracja modelu** - Platt Scaling, Isotonic Regression
2. **Cost-Sensitive Learning** - wbudowanie kosztÃ³w w trening
3. **Analiza feature importance** - ktÃ³re cechy najbardziej wpÅ‚ywajÄ… na churn?
4. **Segmentacja klientÃ³w** - rÃ³Å¼ne thresholdy dla rÃ³Å¼nych segmentÃ³w
5. **Temporal analysis** - jak zmieniajÄ… siÄ™ przewidywania w czasie?
6. **A/B testing** - test threshold 0.5 vs 0.3 na produkcji

---

## ğŸ“š Bibliografia i zasoby

- [PyCaret Documentation - Classification](https://pycaret.gitbook.io/docs/get-started/functions/classification)
- [Scikit-learn - Precision-Recall](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html)
- [IBM Telco Customer Churn Dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

**Autor:** Åukasz  
**Data:** StyczeÅ„ 2026  
**Projekt:** ML Portfolio - Churn Prediction Series
